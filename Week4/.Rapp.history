read.csv("gerber.csv")
gerber = read.csv("gerber.csv")
sum(gerber$voting)
sum(gerber$voting == 1)
table(gerber$voting)
summary(gerber)
108696/(235388+ 108696)
sum(gerber$voting[gerber$civicduty == 1])
sum(gerber$voting[gerber$civicduty == 1])/sum(gerber)
sum(gerber$voting[gerber$civicduty == 1])/sum(gerber$civicduty)
sum(gerber$voting[gerber$civicduty == 1])/sum(gerber$neighbors)
sum(gerber$voting[gerber$neighbors == 1])/sum(gerber$neighbors)
sum(gerber$voting[gerber$hawthorne == 1])/sum(gerber$hawthorne)
sum(gerber$voting[gerber$self == 1])/sum(gerber$self)
model1 = lgm(voting ~ civicduty + neighbors + hawthorne + self, data=berger, method = "class")
model1 = glm(voting ~ civicduty + neighbors + hawthorne + self, data=berger, method = "class")
model1 = glm(voting ~ civicduty + neighbors + hawthorne + self, data=gerber, method = "class")
model1 = glm(voting ~ civicduty + neighbors + hawthorne + self, data=gerber, method="binomial")
model1 = glm(voting ~ civicduty + neighbors + hawthorne + self, data=gerber, family="binomial")
summary(model1)
predictions = predict(model1, gerber)
predictions
predictions = predict(model1, type="response")
predictions
table(gerber$voting, predictions, gerber$voting - predictions > 0.3)
table(gerber$voting, gerber$voting - predictions > 0.3)
table(gerber$voting, gerber$voting - predictions > 0.5)
predictions = predict(model1, data=gerber, type="response")
table(gerber$voting, gerber$voting - predictions > 0.5)
table(gerber$voting, predictions >= 0.5)
table(gerber$voting, predictions >= 0.3)
134513+ 51966
186479/nrow(gerber)
186479+100875+ 56730
186479/344084
table(gerber$voting, predictions >= 0.5)
235388/344084
library(ROCR)
install.packages("ROCR")
library(ROCR)
ROCRpred = prediction(predictions, gerber$voting)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))
auc = as.numeric(performance(ROCRpred, "auc")@y.values)
auc
sum(gerber$voting==0)/sum(gerber)
sum(gerber$voting==0)/nrow(gerber)
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber)
library(rpart)
CARTmodel = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber)
model2 =CARTmodel
plot(model2)
library(rpart.plot)
prp(model2)
model3 = rpart(voting ~ civicduty + hawthorne + self + neighbors, data=gerber, cp=0.0)
prp(model3)
model3 = rpart(voting ~ civicduty + hawthorne + self + neighbors + sex, data=gerber, cp=0.0)
prp(model3)
modelC = rpart(voting ~ control, data=gerber, cp=0.0)
modelCS = rpart(voting ~ control+sex, data=gerber, cp=0.0)
prp(modelC)
prp(modelCS)
prp(modelC)
prp(modelC, digits=6)
abs(0.296638-0.34)
prp(modelCS, digits=6)
model4 = glm(voting ~ control +sex, data= gerber, family="binomial")
summary(model4)
Possibilities = data.frame(sex=c(0,0,1,1),control=c(0,1,0,1))#
predict(model4, newdata=Possibilities, type="response")
abs(0.2908065 - 0.290456)
model5 = glm(voting ~ sex + control + sex:control, data=gerber, family="binomial")
summary(model5)
predict(model5, newdata=Possibilities, type="response")
abs(0.2904558 - 0.290456)
read.csv("letters_ABPR.csv")
letters = read.csv("letters_ABPR.csv")
letters$isB = as.factor(letters$letter == "B")
library(caTools)
set.seed(1000)
split = sample.split(letters$isB, SplitRatio=0.5)
split
train = subset(letters, split==TRUE)
test = subset(letters, split==FALSE)
nrow(test$isB ==0 )
sum(test$isB ==0 )
sum(test$isB ==1 )
nrow(test)
table(test$isB)
1175/(1175)
1175/(1175+383)
CARTb = rpart(isB ~ . - letter, data=train, method="class")
predictions = predict(CARTb, newdata=test, type="class")
table(test$isB, predictions)
1118+340
1458/(90+1458)
install.packages("randomForrest")
install.packages("randomForest")
library(randomForest)
model1 = randomForest(isB ~ . -letter, data=train)
predictions = predict(model1, newdata=test, method="class")
table(test$isB, predictions)
1164+373
/4
1537/(1537+21)
letters$letter = as.factor( letters$letter )
summary(letters)
set.seed(2000)
split =sample.split(letters$letter, SplitRatio = 0.5)
train = subset(letters, split==TRUE)
test =  subset(letters, split==FALSE)
table(test$letter)
401/(401+395+383+379)
model2 = rpart(letter ~ . -isB, data=train, method="class")
predictions = predict(model2, newdata=test, type="class")
table(test$letter, predictions)
(348+318+363+340)/nrow(test)
set.seed(1000)
model3 =randomForest(letter ~ . -isB, data=train, method="class")
predictions = predict(model3, newdata=test, type="class")
table(test$letter, predictions)
(390)
(390+380)
(390+380+393+364)/nrow(test)
census = read.csv("census.csv")
set.seed(2000)
split = sample.split(census$over50k, SplitRatio = 0.6)
train = subset(census, split=TRUE)
test = subset(census, split=FALSE)
model1 = glm(over50k ~ ., data=train, family="binomial")
summary(train)
summary(model1)
summary(census)
model1 = glm(over50k ~ ., data=train)
model1 = glm(over50k ~ ., data=train, family="binomial")
summary(model1)
predictions = predict(model1, newdata=test)
table(test$over50k, preidictions >=0.5)
table(test$over50k, predictions >=0.5)
23381+3690
27071/nrow(test)
train = subset(census, split==TRUE)
test = subset(census, split==FALSE)
model1 = glm(over50k ~ ., data=train, family="binomial")
summary(model1)
predictions = predict(model1, newdata=test)
table(test$over50k, predictions >=0.5)
9351+1515
10866/nrow(test)
9351+362
9713/nrow(test)
libray(ROCR)
library(ROCR)
ROCRpred = prediction(predictions, test$over50k)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))
auc = as.numeric(performance(ROCRpred, "auc")@y.values)
auc
model2 = rpart(over50k ~ ., data=train, metho="class")
model2 = rpart(over50k ~ ., data=train, method="class")
prp(model2)
predictions = predict(model2, newdata=test)
table(test$over50k, predictions>=0.5)
nrow(test$over50k)
test$over50k
nrow(predictions)
predictions
table(test$over50k, predictions[,2]>=0.5)
table(test$over50k, predictions[,2]>=0.5)
test$over50k
table(test$over50k, predictions[,2]>=0.5)
9243+1596
10839/nrow(predictions)
ROCRpred = prediction(predictions, test$over50k)
ROCRpred = prediction(predictions[,2], test$over50k)
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,0.1), text.adj=c(-0.2,1.7))
auc = as.numeric(performance(ROCRpred, "auc")@y.values)
auc
set.seed(1)#
#
trainSmall = train[sample(nrow(train), 2000), ]
set.seed(1)
model3 = randomForest(over50k ~ ., data=trainSmall)
predictions = predict(model3, newdata=test)
table(test$over50k, predictions[,2] >=0.5)
table(test$over50k, predictions[,2]>=0.5)
predictions
table(test$over50k, predictions>=0.5)
table(test$over50k, predictions)
9586+ 1093
10679/nrow(predictions)
10679/(10679+1985+1093)
vu = varUsed(model3, count=TRUE)
vusorted = sort(vu, decreasing = FALSE, index.return = TRUE)
dotchart(vusorted$x, names(model3$forest$xlevels[vusorted$ix]))
varImpPlot(model3)
set.seed(2)
cartGrid = expand.grid( .cp = seq(0.002,0.1,0.002))
cartGrid
install.packages("caret")#
library(caret)#
install.packages("e1071")#
library(e1071)
numFolds = trainControl( method = "cv", number = 10 )
train(over50k ~ ., data = train, method = "rpart", trControl = numFolds, tuneGrid = cpGrid )
train(over50k ~ ., data = train, method = "rpart", trControl = numFolds, tuneGrid = cartGrid )
model4 = rpart(over50k ~ ., data=train, method="class", cp=0.002)
predictions =predict(model4, newdata=test)
table(test$over50k, predictions)
table(test$over50k, predictions[0,2])
table(test$over50k, predictions[0,2]>0.5)
table(test$over50k, predictions[0,2]>=0.5)
predictions
test$over50k
table(test$over50k, predictions[,2]>=0.5)
9178+1838
11016/(11016+535+1240)
prp(model4)
